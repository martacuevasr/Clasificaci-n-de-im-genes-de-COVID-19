{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33866 images belonging to 4 classes.\n",
      "Found 8464 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m1059/1059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 531ms/step - accuracy: 0.6817 - loss: 0.8502 - val_accuracy: 0.7413 - val_loss: 1.3015\n",
      "Epoch 2/20\n",
      "\u001b[1m 368/1059\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:35\u001b[0m 486ms/step - accuracy: 0.7654 - loss: 0.6234"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Configuración inicial\n",
    "image_size = (128, 128)  # Tamaño de las imágenes para redimensionar\n",
    "batch_size = 32\n",
    "\n",
    "# Ruta al dataset (ajusta esto a tu entorno)\n",
    "dataset_path = \"./COVID-19_Radiography_Dataset\"\n",
    "\n",
    "# Subcarpetas de las clases\n",
    "categories = [\"COVID\", \"NORMAL\", \"PNEUMONIA\", \"Lung_Opacity\"]\n",
    "\n",
    "# Configurar generador de datos con aumento\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=5,  # Reduce rotación\n",
    "    width_shift_range=0.05,  # Reduce desplazamiento\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "# Crear generadores para entrenamiento y validación\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Cargar el modelo MobileNetV2 preentrenado sin las capas superiores\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Congelar las capas de la base\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:  # Congela la mayoría, pero descongela las últimas 50 capas\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# Construir el modelo\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Configurar Early Stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluar en el conjunto de validación\n",
    "test_loss, test_acc = model.evaluate(val_generator, verbose=2)\n",
    "print(f\"Exactitud en validación: {test_acc:.2f}\")\n",
    "\n",
    "# Graficar curvas de entrenamiento y validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Exactitud entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Exactitud validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.legend()\n",
    "plt.title('Curvas de entrenamiento y validación')\n",
    "plt.show()\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"\\nMatriz de confusión:\\n\", cm)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"\\nInforme de clasificación:\\n\", classification_report(y_true, y_pred_classes, target_names=categories))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
