{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Configuración inicial\n",
    "image_size = (150, 150)  # Tamaño de las imágenes para redimensionar\n",
    "batch_size = 32\n",
    "\n",
    "# Ruta al dataset (ajusta esto a tu entorno)\n",
    "dataset_path = \"./COVID-19 Radiography Database\"\n",
    "\n",
    "# Preparación de los datos\n",
    "categories = [\"NORMAL\", \"COVID\", \"LUNG_OPACITY\", \"VIRAL_PNEUMONIA\"]\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    folder_path = os.path.join(dataset_path, category)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "            data.append(img_array)\n",
    "            labels.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {img_path}: {e}\")\n",
    "\n",
    "# Conversión a arrays de NumPy\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Dividir conjunto de validación\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "# Aumento de datos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Crear generadores\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(val_images, val_labels, batch_size=batch_size)\n",
    "\n",
    "# Crear el modelo\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Configurar Early Stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Exactitud en prueba: {test_acc:.2f}\")\n",
    "\n",
    "# Graficar curvas de entrenamiento y validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Exactitud entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Exactitud validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.legend()\n",
    "plt.title('Curvas de entrenamiento y validación')\n",
    "plt.show()\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(test_images)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(test_labels, y_pred_classes)\n",
    "print(\"\\nMatriz de confusión:\\n\", cm)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"\\nInforme de clasificación:\\n\", classification_report(test_labels, y_pred_classes, target_names=categories))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
